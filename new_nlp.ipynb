{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOI+UIX/LNAoj7IloFinjjq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prathamesh170206/DarkPhantom.github.io/blob/main/new_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "xh6W3VTpdLDV",
        "outputId": "bcf6c23a-fb0e-4b91-898a-c4ed2d801a3e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-928a41ed-2c3e-4ba0-82a2-f80dd796b303\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-928a41ed-2c3e-4ba0-82a2-f80dd796b303\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving test_prompts_orders.json to test_prompts_orders.json\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Disable external logging/telemetry that prompts for API keys\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n",
        "\n",
        "import json\n",
        "import random\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification, Trainer, TrainingArguments\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "# -------------------------------\n",
        "# Config\n",
        "# -------------------------------\n",
        "data_path = \"/content/sample_data/hq_orders_augmented_2000.json\"\n",
        "model_save_path = \"/content/saved_models\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "POKEMON = [\"Bulbasaur\", \"Charizard\", \"Pikachu\", \"Mewtwo\"]\n",
        "\n",
        "# Manual label mapping to preserve order\n",
        "label2idx = {label: idx for idx, label in enumerate(POKEMON)}\n",
        "idx2label = {idx: label for idx, label in enumerate(POKEMON)}\n",
        "\n",
        "print(\"POKEMON list order:\", POKEMON)\n",
        "print(\"Manual label2idx mapping:\", label2idx)\n",
        "\n",
        "# Seed\n",
        "def set_seed(seed):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "set_seed(42)\n",
        "\n",
        "# Load data\n",
        "with open(data_path) as f:\n",
        "    hq_orders = json.load(f)\n",
        "\n",
        "random.shuffle(hq_orders)\n",
        "test_orders = hq_orders[:100]\n",
        "val_orders = hq_orders[100:200]\n",
        "train_orders = hq_orders[200:]\n",
        "\n",
        "# MultiLabelBinarizer for protect labels\n",
        "mlb_protect = MultiLabelBinarizer(classes=POKEMON)\n",
        "mlb_protect.fit([POKEMON])\n",
        "\n",
        "# Dataset class with NO .to(device) in __getitem__\n",
        "class HQDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, task=\"target\", max_length=128):\n",
        "        self.prompts = [d[\"prompt\"] for d in data]\n",
        "        self.task = task\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "        if task == \"target\":\n",
        "            self.labels = [label2idx[d[\"target\"]] for d in data]\n",
        "        elif task == \"protect\":\n",
        "            self.labels = []\n",
        "            for d in data:\n",
        "                protected = d.get(\"protected\", [])\n",
        "                if isinstance(protected, str):\n",
        "                    protected = [protected]\n",
        "                elif protected is None:\n",
        "                    protected = []\n",
        "                vec = mlb_protect.transform([protected])[0]\n",
        "                self.labels.append(vec)\n",
        "        else:\n",
        "            raise ValueError(\"Task must be 'target' or 'protect'\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.prompts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        prompt = self.prompts[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            prompt,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        item = {key: val.squeeze() for key, val in encoding.items()}\n",
        "        item[\"labels\"] = torch.tensor(\n",
        "            self.labels[idx],\n",
        "            dtype=torch.long if self.task == \"target\" else torch.float\n",
        "        )\n",
        "        return item\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
        "\n",
        "train_dataset_target = HQDataset(train_orders, tokenizer, task=\"target\")\n",
        "val_dataset_target = HQDataset(val_orders, tokenizer, task=\"target\")\n",
        "test_dataset_target = HQDataset(test_orders, tokenizer, task=\"target\")\n",
        "\n",
        "train_dataset_protect = HQDataset(train_orders, tokenizer, task=\"protect\")\n",
        "val_dataset_protect = HQDataset(val_orders, tokenizer, task=\"protect\")\n",
        "test_dataset_protect = HQDataset(test_orders, tokenizer, task=\"protect\")\n",
        "\n",
        "# Helper: load fine-tuned model if available, else init base\n",
        "def load_or_init_target():\n",
        "    ckpt_dir = model_save_path + \"_target\"\n",
        "    if os.path.isdir(ckpt_dir) and os.path.isfile(os.path.join(ckpt_dir, \"config.json\")):\n",
        "        print(f\"Loading fine-tuned target model from {ckpt_dir}\")\n",
        "        return RobertaForSequenceClassification.from_pretrained(ckpt_dir).to(device)\n",
        "    else:\n",
        "        print(\"No fine-tuned target checkpoint found. Initializing from roberta-base.\")\n",
        "        return RobertaForSequenceClassification.from_pretrained(\n",
        "            \"roberta-base\", num_labels=len(POKEMON)\n",
        "        ).to(device)\n",
        "\n",
        "def load_or_init_protect():\n",
        "    ckpt_dir = model_save_path + \"_protect\"\n",
        "    if os.path.isdir(ckpt_dir) and os.path.isfile(os.path.join(ckpt_dir, \"config.json\")):\n",
        "        print(f\"Loading fine-tuned protect model from {ckpt_dir}\")\n",
        "        return RobertaForSequenceClassification.from_pretrained(ckpt_dir).to(device)\n",
        "    else:\n",
        "        print(\"No fine-tuned protect checkpoint found. Initializing from roberta-base.\")\n",
        "        return RobertaForSequenceClassification.from_pretrained(\n",
        "            \"roberta-base\", num_labels=len(POKEMON), problem_type=\"multi_label_classification\"\n",
        "        ).to(device)\n",
        "\n",
        "# Models\n",
        "model_target = load_or_init_target()\n",
        "model_protect = load_or_init_protect()\n",
        "\n",
        "# Class weights calculation\n",
        "from collections import Counter\n",
        "counts = Counter([d[\"target\"] for d in train_orders])\n",
        "total = sum(counts.values())\n",
        "class_weights = [total / counts[cls] for cls in POKEMON]\n",
        "class_weights_tensor = torch.tensor(class_weights).to(device)\n",
        "print(f\"Class weights: {class_weights}\")\n",
        "\n",
        "# Custom Trainer with weighted loss\n",
        "class WeightedTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.get(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        if model.config.problem_type == \"multi_label_classification\":\n",
        "            loss_fct = torch.nn.BCEWithLogitsLoss()\n",
        "            loss = loss_fct(logits, labels)\n",
        "        else:\n",
        "            loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
        "            loss = loss_fct(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "# Metrics\n",
        "def compute_metrics_target(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    acc = (preds == labels).mean()\n",
        "    return {\"accuracy\": acc}\n",
        "\n",
        "def compute_metrics_protect(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    probs = torch.sigmoid(torch.tensor(logits))\n",
        "    preds = (probs > 0.5).numpy()\n",
        "    acc = np.mean(np.all(preds == labels, axis=1))\n",
        "    return {\"exact_match_accuracy\": acc}\n",
        "\n",
        "# Training args with report_to=\"none\" to silence external integrations\n",
        "training_args_target = TrainingArguments(\n",
        "    output_dir=model_save_path + \"_target\",\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=model_save_path + \"_logs_target\",\n",
        "    learning_rate=1e-5,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    greater_is_better=True,\n",
        "    fp16=True,\n",
        "    gradient_accumulation_steps=2,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "training_args_protect = TrainingArguments(\n",
        "    output_dir=model_save_path + \"_protect\",\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_dir=model_save_path + \"_logs_protect\",\n",
        "    learning_rate=1e-5,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"exact_match_accuracy\",\n",
        "    greater_is_better=True,\n",
        "    fp16=True,\n",
        "    gradient_accumulation_steps=2,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer_target = WeightedTrainer(\n",
        "    model=model_target,\n",
        "    args=training_args_target,\n",
        "    train_dataset=train_dataset_target,\n",
        "    eval_dataset=val_dataset_target,\n",
        "    compute_metrics=compute_metrics_target\n",
        ")\n",
        "\n",
        "trainer_protect = Trainer(\n",
        "    model=model_protect,\n",
        "    args=training_args_protect,\n",
        "    train_dataset=train_dataset_protect,\n",
        "    eval_dataset=val_dataset_protect,\n",
        "    compute_metrics=compute_metrics_protect\n",
        ")\n",
        "\n",
        "# Train or skip; if skipped, we still have loaded fine-tuned models if present\n",
        "#trainer_target.train()\n",
        "trainer_target.save_model(model_save_path + \"_target\")\n",
        "#trainer_protect.train()\n",
        "trainer_protect.save_model(model_save_path + \"_protect\")\n",
        "\n",
        "print(\"Setup complete. Models are ready (loaded from checkpoints if available).\")\n",
        "\n",
        "\n",
        "# Interactive predict loop\n",
        "print(\"\\n=== HQ Order Prediction ===\\nType your HQ order prompt and press Enter. Type 'exit' to quit.\\n\")\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"Enter HQ order prompt: \")\n",
        "    if user_input.lower() == \"exit\":\n",
        "        print(\"Exiting...\")\n",
        "        break\n",
        "\n",
        "    encoding = tokenizer(\n",
        "        user_input,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=128,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "    encoding = {k: v.to(device) for k, v in encoding.items()}\n",
        "\n",
        "    model_target.eval()\n",
        "    with torch.no_grad():\n",
        "        output_target = model_target(**encoding)\n",
        "        logits = output_target.logits.cpu().numpy()\n",
        "        target_idx = int(np.argmax(logits, axis=1)[0])\n",
        "        target_pokemon = idx2label[target_idx]\n",
        "\n",
        "    model_protect.eval()\n",
        "    with torch.no_grad():\n",
        "        output_protect = model_protect(**encoding)\n",
        "        probs = torch.sigmoid(output_protect.logits)\n",
        "        protected_idx = (probs > 0.5).cpu().numpy()\n",
        "        protected_pokemon = mlb_protect.inverse_transform(protected_idx)[0]\n",
        "\n",
        "    print(f\"\\nPredicted Target: {target_pokemon}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWklg8ZRjfYA",
        "outputId": "71ec9f2f-e07c-4d00-8489-ce6ce1e79a24"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "POKEMON list order: ['Bulbasaur', 'Charizard', 'Pikachu', 'Mewtwo']\n",
            "Manual label2idx mapping: {'Bulbasaur': 0, 'Charizard': 1, 'Pikachu': 2, 'Mewtwo': 3}\n",
            "Loading fine-tuned target model from /content/saved_models_target\n",
            "Loading fine-tuned protect model from /content/saved_models_protect\n",
            "Class weights: [4.209445585215605, 3.4569983136593594, 4.141414141414141, 4.315789473684211]\n",
            "Setup complete. Models are ready (loaded from checkpoints if available).\n",
            "UTF-8 load failed: 'utf-8' codec can't decode byte 0x92 in position 13990: invalid start byte\n",
            "Loaded 200 prompts from /content/test_prompts_orders.json\n",
            "Wrote 200 targets to /content/saved_models\n",
            "\n",
            "=== HQ Order Prediction ===\n",
            "Type your HQ order prompt and press Enter. Type 'exit' to quit.\n",
            "\n",
            "Enter HQ order prompt: HQ REPORT: Situation analysis regarding unusual activity of scaled fire titan in this operational zone. Draw minimal bloodline; photographic evidence is priority. Use thermal masking as a decoy if pursuit is necessary. Scouts described sightings of Charizard moving in small clusters, often accompanied by subtle disruptions in the environment. Reports from scouts mention hostile encounters but details remain unclear. Scouts described sightings of orange lizard moving in small clusters, often accompanied by subtle disruptions in the environment. Scouts described sightings of flame dragon moving in small clusters, often accompanied by subtle disruptions in the environment. Radio checkpoint at 02:00 to confirm continued presence. Re-route patrols to avoid recurring sinkholes along Route 3. Use nonlethal methods when the objective allows for capture. Local sensors report intermittent EM spikes across grid 7K. HQ analysts believe these disturbances are precursors to a larger conflict. Scouts described sightings of flame dragon moving in small clusters, often accompanied by subtle disruptions in the environment. Radio checkpoint at 02:00 to confirm continued presence. Extract value intelligence before demolition where possible. HQ orders: neutralize the scaled fire titan population in the vicinity and secure evidence. Mark LZ candidates; do not land within visible ashfall. Confirm identity via both visual and acoustic signatures. Scouts described sightings of scaled fire titan moving in small clusters, often accompanied by subtle disruptions in the environment. Additional activity has been noted from genetic experiment groups nearby, though they do not appear hostile at present. Local sensors report intermittent EM spikes across grid 7K. Scouts described sightings of winged inferno moving in small clusters, often accompanied by subtle disruptions in the environment. This regionï¿½s flora contains irritants; PPE is advised for all personnel. Additional activity has been noted from electric rat groups nearby, though they do not appear hostile at present. Small scuffle reported at the eastern fence line; no human injury. Scouts described sightings of flame dragon moving in small clusters, often accompanied by subtle disruptions in the environment. Use hand signals when verbal comms might reveal position. Additional activity has been noted from sprout toad groups nearby, though they do not appear hostile at present. Scouts described sightings of scaled fire titan moving in small clusters, often accompanied by subtle disruptions in the environment. Long-range sensors indicate sporadic bursts of radiation, possibly linked to latent evolutions. Scouts described sightings of winged inferno moving in small clusters, often accompanied by subtle disruptions in the environment. This sector has intermittent interference from legacy comm buoys. Additional activity has been noted from green seedling groups nearby, though they do not appear hostile at present. Scouts described sightings of orange lizard moving in small clusters, often accompanied by subtle disruptions in the environment. Scouts described sightings of flame dragon moving in small clusters, often accompanied by subtle disruptions in the environment. Scouts described sightings of winged inferno moving in small clusters, often accompanied by subtle disruptions in the environment. Scouts described sightings of orange lizard moving in small clusters, often accompanied by subtle disruptions in the environment. Additional activity has been noted from green seedling groups nearby, though they do not appear hostile at present. Maintain a 50m standoff from volatile flora. Additional activity has been noted from tiny thunder beast groups nearby, though they do not appear hostile at present. Maintain operational secrecy. HQ will expect a full after-action report.\"\n",
            "\n",
            "Predicted Target: Charizard\n",
            "Enter HQ order prompt: HQ REPORT: Situation analysis regarding unusual activity of vine beast in this operational zone. Keep monitoring the skies - aerial disturbances are not uncommon in this sector. Civilians in nearby settlements are growing anxious and require reassurance. Communications are patchy; maintain line-of-sight whenever possible. Thermal cameras logged irregular heat signatures near the treeline. Scouts described sightings of green seedling moving in small clusters, often accompanied by subtle disruptions in the environment. Additional activity has been noted from psychic clone groups nearby, though they do not appear hostile at present. Small salvageable components can be turned over to engineering. Calm, low-frequency calls appear to pacify the group temporarily. Target behavior escalates when food sources are nearby. Additional activity has been noted from rodent of sparks groups nearby, though they do not appear hostile at present. Secondary objective: deny access to the water supply, if feasible. Calm, low-frequency calls appear to pacify the group temporarily. If the target flees, pursue only after authorization from overwatch. Confirm identity via both visual and acoustic signatures. Re-route patrols to avoid recurring sinkholes along Route 3. Use soft approach; loud noises cause scattering behavior. Radio checkpoint at 02:00 to confirm continued presence. Immediate action: destroy the green seedling to prevent further environmental damage. Scouts described sightings of Bulbasaur moving in small clusters, often accompanied by subtle disruptions in the environment. Keep ambient light low to maintain night-ops concealment. Scouts described sightings of plant reptile moving in small clusters, often accompanied by subtle disruptions in the environment. Scouts described sightings of green seedling moving in small clusters, often accompanied by subtle disruptions in the environment. Scouts described sightings of plant reptile moving in small clusters, often accompanied by subtle disruptions in the environment. Scouts described sightings of plant reptile moving in small clusters, often accompanied by subtle disruptions in the environment. Do not engage until ROE (Rules of Engagement) confirmed by HQ. Scouts described sightings of vine beast moving in small clusters, often accompanied by subtle disruptions in the environment. Additional activity has been noted from scaled fire titan groups nearby, though they do not appear hostile at present. Scouts described sightings of plant reptile moving in small clusters, often accompanied by subtle disruptions in the environment. Additional activity has been noted from scaled fire titan groups nearby, though they do not appear hostile at present. If the target flees, pursue only after authorization from overwatch. Additional activity has been noted from synthetic mind weapon groups nearby, though they do not appear hostile at present. Additional activity has been noted from genetic experiment groups nearby, though they do not appear hostile at present. Scouts described sightings of sprout toad moving in small clusters, often accompanied by subtle disruptions in the environment. Use nonlethal methods when the objective allows for capture. Small salvageable components can be turned over to engineering. Additional activity has been noted from rodent of sparks groups nearby, though they do not appear hostile at present. Watch for electrical discharges - avoid metal conduits during storms. Scouts described sightings of sprout toad moving in small clusters, often accompanied by subtle disruptions in the environment. Scouts described sightings of sprout toad moving in small clusters, often accompanied by subtle disruptions in the environment. Maintain operational secrecy. HQ will expect a full after-action report.\"\n",
            "\n",
            "Predicted Target: Bulbasaur\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "zip_base = \"/content/saved_models_target\"\n",
        "zip_path = \"/content/saved_models_target.zip\"\n",
        "shutil.make_archive(zip_base, \"zip\", zip_base)  # creates /content/saved_models_target.zip\n",
        "\n",
        "from google.colab import files\n",
        "files.download(zip_path)\n"
      ],
      "metadata": {
        "id": "G-IXDw1-HaLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "# Disable external logging/telemetry\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n",
        "\n",
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# Config\n",
        "# -------------------------------\n",
        "data_path = \"/content/sample_data/hq_orders_augmented_2000.json\"\n",
        "model_save_path = \"/content/saved_models_2\"  # base path (will append _target)\n",
        "target_ckpt_dir = model_save_path + \"_target\"\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "POKEMON = [\"Bulbasaur\", \"Charizard\", \"Pikachu\", \"Mewtwo\"]\n",
        "label2idx = {label: idx for idx, label in enumerate(POKEMON)}\n",
        "idx2label = {idx: label for idx, label in enumerate(POKEMON)}\n",
        "print(\"POKEMON list order:\", POKEMON)\n",
        "print(\"Manual label2idx mapping:\", label2idx)\n",
        "\n",
        "# -------------------------------\n",
        "# Reproducibility\n",
        "# -------------------------------\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "# -------------------------------\n",
        "# Load data\n",
        "# -------------------------------\n",
        "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    hq_orders = json.load(f)\n",
        "\n",
        "texts = [d[\"prompt\"] for d in hq_orders]\n",
        "targets = [d[\"target\"] for d in hq_orders]\n",
        "\n",
        "# Stratified 80/10/10 split\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "    texts, targets, test_size=0.2, random_state=42, stratify=targets\n",
        ")\n",
        "X_val, X_test, y_val, y_test = train_test_split(\n",
        "    X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp\n",
        ")\n",
        "\n",
        "train_orders = [{\"prompt\": p, \"target\": t} for p, t in zip(X_train, y_train)]\n",
        "val_orders   = [{\"prompt\": p, \"target\": t} for p, t in zip(X_val, y_val)]\n",
        "test_orders  = [{\"prompt\": p, \"target\": t} for p, t in zip(X_test, y_test)]\n",
        "\n",
        "# -------------------------------\n",
        "# Dataset\n",
        "# -------------------------------\n",
        "MAX_LEN = 192  # increase if VRAM allows\n",
        "\n",
        "class HQDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length=MAX_LEN):\n",
        "        self.prompts = [d[\"prompt\"] for d in data]\n",
        "        self.labels = [label2idx[d[\"target\"]] for d in data]\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "    def __len__(self):\n",
        "        return len(self.prompts)\n",
        "    def __getitem__(self, idx):\n",
        "        enc = self.tokenizer(\n",
        "            self.prompts[idx],\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        item = {k: v.squeeze(0) for k, v in enc.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "# -------------------------------\n",
        "# Tokenizer & Model (DeBERTa v3 base)\n",
        "# -------------------------------\n",
        "base_model_name = \"microsoft/deberta-v3-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_name)\n",
        "\n",
        "train_dataset = HQDataset(train_orders, tokenizer, max_length=MAX_LEN)\n",
        "val_dataset   = HQDataset(val_orders, tokenizer, max_length=MAX_LEN)\n",
        "test_dataset  = HQDataset(test_orders, tokenizer, max_length=MAX_LEN)\n",
        "\n",
        "def load_or_init_model():\n",
        "    if os.path.isdir(target_ckpt_dir) and os.path.isfile(os.path.join(target_ckpt_dir, \"config.json\")):\n",
        "        print(f\"Loading fine-tuned model from {target_ckpt_dir}\")\n",
        "        return AutoModelForSequenceClassification.from_pretrained(target_ckpt_dir).to(device)\n",
        "    else:\n",
        "        print(\"No checkpoint found. Initializing from base.\")\n",
        "        return AutoModelForSequenceClassification.from_pretrained(\n",
        "            base_model_name, num_labels=len(POKEMON)\n",
        "        ).to(device)\n",
        "\n",
        "model = load_or_init_model()\n",
        "\n",
        "# -------------------------------\n",
        "# Class weights from train only (capped)\n",
        "# -------------------------------\n",
        "counts = Counter(y_train)\n",
        "total = sum(counts.values())\n",
        "max_w = 5.0\n",
        "class_weights = [min(total / counts[c], max_w) for c in POKEMON]\n",
        "class_weights_tensor = torch.tensor(class_weights).to(device)\n",
        "print(\"Class counts:\", dict(counts))\n",
        "print(\"Class weights (capped):\", class_weights)\n",
        "\n",
        "# -------------------------------\n",
        "# Metrics\n",
        "# -------------------------------\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=-1)\n",
        "    acc = (preds == labels).mean()\n",
        "    return {\"accuracy\": acc}\n",
        "\n",
        "# -------------------------------\n",
        "# Trainer with safe loss (no fp16, no checkpointing)\n",
        "# -------------------------------\n",
        "class WeightedTrainer(Trainer):\n",
        "    def __init__(self, *args, label_smoothing=0.05, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.label_smoothing = float(label_smoothing)\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        # Extract labels and ensure correct type/device\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        labels = labels.to(model.device).long().contiguous()\n",
        "\n",
        "        # Forward pass on remaining inputs\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits  # [B, C]\n",
        "\n",
        "        # Fresh class weights each step on correct device\n",
        "        cw = class_weights_tensor.to(logits.device)\n",
        "\n",
        "        if self.label_smoothing > 0.0:\n",
        "            num_classes = logits.size(-1)\n",
        "            smooth = self.label_smoothing\n",
        "            with torch.no_grad():\n",
        "                true_dist = torch.full_like(logits, smooth / (num_classes - 1))\n",
        "                true_dist.scatter_(1, labels.unsqueeze(1), 1.0 - smooth)\n",
        "            log_probs = torch.nn.functional.log_softmax(logits, dim=-1)\n",
        "            loss_per_class = -(true_dist * log_probs)                 # no grad via true_dist\n",
        "            loss = (loss_per_class * cw.unsqueeze(0)).sum(-1).mean()  # weighted mean\n",
        "        else:\n",
        "            ce = torch.nn.CrossEntropyLoss(weight=cw)\n",
        "            loss = ce(logits.view(-1, logits.size(-1)), labels.view(-1))\n",
        "\n",
        "        if return_outputs:\n",
        "            return loss, outputs\n",
        "        return loss\n",
        "\n",
        "# -------------------------------\n",
        "# TrainingArguments with fixed LR (\"vectorizer\"-style)\n",
        "# -------------------------------\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=target_ckpt_dir,\n",
        "    num_train_epochs=8,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=32,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    logging_strategy=\"steps\",\n",
        "    logging_steps=50,\n",
        "    learning_rate=2e-5,            # fixed LR, no scheduler\n",
        "    lr_scheduler_type=\"constant\",  # fixed LR\n",
        "    warmup_ratio=0.0,              # no warmup\n",
        "    weight_decay=0.0,              # no weight decay\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    greater_is_better=True,\n",
        "    gradient_accumulation_steps=2,\n",
        "    max_grad_norm=1.0,\n",
        "    fp16=False,\n",
        "    bf16=False,\n",
        "    gradient_checkpointing=False,\n",
        "    report_to=\"none\",\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "trainer = WeightedTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)],\n",
        "    label_smoothing=0.05\n",
        ")\n",
        "\n",
        "# -------------------------------\n",
        "# Train, save, evaluate\n",
        "# -------------------------------\n",
        "#trainer.train()\n",
        "trainer.save_model(target_ckpt_dir)\n",
        "\n",
        "val_metrics = trainer.evaluate(eval_dataset=val_dataset)\n",
        "test_metrics = trainer.evaluate(eval_dataset=test_dataset)\n",
        "print(\"Validation metrics:\", val_metrics)\n",
        "print(\"Test metrics:\", test_metrics)\n",
        "\n",
        "# -------------------------------\n",
        "# Reload for inference (explicit)\n",
        "# -------------------------------\n",
        "print(\"\\nReloading best checkpoint for inference...\")\n",
        "inference_model = AutoModelForSequenceClassification.from_pretrained(target_ckpt_dir).to(device)\n",
        "inference_model.eval()\n",
        "\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Windows paths\n",
        "input_json = \"/content/test_prompts_orders.json\"\n",
        "output_txt = \"/content/saved_models_2\"\n",
        "\n",
        "def load_json_robust(path):\n",
        "    # Try UTF-8 first (with BOM strip)\n",
        "    try:\n",
        "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "            text = f.read()\n",
        "        if text and text[0] == \"\\ufeff\":\n",
        "            text = text.lstrip(\"\\ufeff\")\n",
        "        return json.loads(text)\n",
        "    except Exception as e_utf8:\n",
        "        print(f\"UTF-8 load failed: {e_utf8}\")\n",
        "\n",
        "    # Try cp1252 (Windows-1252)\n",
        "    try:\n",
        "        with open(path, \"r\", encoding=\"cp1252\", errors=\"strict\") as f:\n",
        "            text = f.read()\n",
        "        if text and text[0] == \"\\ufeff\":\n",
        "            text = text.lstrip(\"\\ufeff\")\n",
        "        return json.loads(text)\n",
        "    except Exception as e_cp:\n",
        "        print(f\"cp1252 load failed: {e_cp}\")\n",
        "\n",
        "    # Try JSON Lines with UTF-8\n",
        "    items = []\n",
        "    try:\n",
        "        with open(path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "                items.append(json.loads(line))\n",
        "        if items:\n",
        "            print(\"Loaded as UTF-8 JSONL\")\n",
        "            return items\n",
        "    except Exception as e_jl_utf8:\n",
        "        print(f\"UTF-8 JSONL failed: {e_jl_utf8}\")\n",
        "\n",
        "    # Try JSON Lines with cp1252\n",
        "    try:\n",
        "        with open(path, \"r\", encoding=\"cp1252\", errors=\"replace\") as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "                items.append(json.loads(line))\n",
        "        if items:\n",
        "            print(\"Loaded as cp1252 JSONL\")\n",
        "            return items\n",
        "    except Exception as e_jl_cp:\n",
        "        print(f\"cp1252 JSONL failed: {e_jl_cp}\")\n",
        "\n",
        "    raise RuntimeError(f\"Could not parse JSON at {path} with UTF-8/cp1252 or JSONL.\")\n",
        "\n",
        "class PromptOnlyDataset(Dataset):\n",
        "    def __init__(self, prompts, tokenizer, max_length=128):\n",
        "        self.prompts = prompts\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "    def __len__(self):\n",
        "        return len(self.prompts)\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.prompts[idx]\n",
        "        enc = tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {k: v.squeeze(0) for k, v in enc.items()}\n",
        "\n",
        "def write_targets_for_orders_json(json_path, output_path, batch_size=64):\n",
        "    data = load_json_robust(json_path)\n",
        "\n",
        "    # Support dict-wrapped formats\n",
        "    if isinstance(data, dict):\n",
        "        for k in (\"items\", \"data\", \"orders\"):\n",
        "            if k in data and isinstance(data[k], list):\n",
        "                data = data[k]\n",
        "                break\n",
        "\n",
        "    prompts = [d[\"prompt\"] for d in data if isinstance(d, dict) and \"prompt\" in d]\n",
        "    print(f\"Loaded {len(prompts)} prompts from {json_path}\")\n",
        "\n",
        "    ds = PromptOnlyDataset(prompts, tokenizer, max_length=128)\n",
        "    dl = DataLoader(ds, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model_target.eval()\n",
        "    pred_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in dl:\n",
        "            inputs = {k: v.to(device) for k, v in batch.items()}\n",
        "            logits = model_target(**inputs).logits\n",
        "            pred_idx = torch.argmax(logits, dim=1).cpu().tolist()\n",
        "            pred_labels.extend([idx2label[i] for i in pred_idx])\n",
        "\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for lbl in pred_labels:\n",
        "            f.write(f\"{lbl}\\n\")\n",
        "\n",
        "    print(f\"Wrote {len(pred_labels)} targets to {output_path}\")\n",
        "\n",
        "# Run once to create the output file\n",
        "write_targets_for_orders_json(input_json, output_txt, batch_size=64)\n",
        "# -------------------------------\n",
        "# Interactive predict loop (uses reloaded model)\n",
        "# -------------------------------\n",
        "print(\"\\n=== HQ Order Prediction (type 'exit' to quit) ===\\n\")\n",
        "while True:\n",
        "    user_input = input(\"Enter HQ order prompt: \")\n",
        "    if user_input.lower().strip() == \"exit\":\n",
        "        print(\"Exiting...\")\n",
        "        break\n",
        "    enc = tokenizer(\n",
        "        user_input, truncation=True, padding=\"max_length\",\n",
        "        max_length=MAX_LEN, return_tensors=\"pt\"\n",
        "    )\n",
        "    enc = {k: v.to(device) for k, v in enc.items()}\n",
        "    with torch.no_grad():\n",
        "        logits = inference_model(**enc).logits\n",
        "        target_idx = int(torch.argmax(logits, dim=1).item())\n",
        "    print(f\"Predicted Target: {idx2label[target_idx]}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 727
        },
        "id": "Mh_2Hmb5zn4E",
        "outputId": "983f080a-1f02-412f-db39-fd1fda6ea05e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "POKEMON list order: ['Bulbasaur', 'Charizard', 'Pikachu', 'Mewtwo']\n",
            "Manual label2idx mapping: {'Bulbasaur': 0, 'Charizard': 1, 'Pikachu': 2, 'Mewtwo': 3}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading fine-tuned model from /content/saved_models_2_target\n",
            "Class counts: {'Mewtwo': 420, 'Charizard': 532, 'Pikachu': 428, 'Bulbasaur': 420}\n",
            "Class weights (capped): [4.285714285714286, 3.3834586466165413, 4.205607476635514, 4.285714285714286]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='16' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [8/8 00:06]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation metrics: {'eval_loss': 1.0344481468200684, 'eval_model_preparation_time': 0.0053, 'eval_accuracy': 1.0, 'eval_runtime': 3.554, 'eval_samples_per_second': 63.309, 'eval_steps_per_second': 2.251}\n",
            "Test metrics: {'eval_loss': 1.0343306064605713, 'eval_model_preparation_time': 0.0053, 'eval_accuracy': 1.0, 'eval_runtime': 3.4677, 'eval_samples_per_second': 64.884, 'eval_steps_per_second': 2.307}\n",
            "\n",
            "Reloading best checkpoint for inference...\n",
            "UTF-8 load failed: 'utf-8' codec can't decode byte 0x92 in position 13990: invalid start byte\n",
            "Loaded 200 prompts from /content/test_prompts_orders.json\n",
            "Wrote 200 targets to /content/saved_models_2\n",
            "\n",
            "=== HQ Order Prediction (type 'exit' to quit) ===\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1706963603.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n=== HQ Order Prediction (type 'exit' to quit) ===\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m     \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Enter HQ order prompt: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muser_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"exit\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Exiting...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Windows paths\n",
        "input_json = \"/content/test_prompts_orders.json\"\n",
        "output_txt = \"/content/saved_models\"\n",
        "\n",
        "def load_json_robust(path):\n",
        "    # Try UTF-8 first (with BOM strip)\n",
        "    try:\n",
        "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "            text = f.read()\n",
        "        if text and text[0] == \"\\ufeff\":\n",
        "            text = text.lstrip(\"\\ufeff\")\n",
        "        return json.loads(text)\n",
        "    except Exception as e_utf8:\n",
        "        print(f\"UTF-8 load failed: {e_utf8}\")\n",
        "\n",
        "    # Try cp1252 (Windows-1252)\n",
        "    try:\n",
        "        with open(path, \"r\", encoding=\"cp1252\", errors=\"strict\") as f:\n",
        "            text = f.read()\n",
        "        if text and text[0] == \"\\ufeff\":\n",
        "            text = text.lstrip(\"\\ufeff\")\n",
        "        return json.loads(text)\n",
        "    except Exception as e_cp:\n",
        "        print(f\"cp1252 load failed: {e_cp}\")\n",
        "\n",
        "    # Try JSON Lines with UTF-8\n",
        "    items = []\n",
        "    try:\n",
        "        with open(path, \"r\", encoding=\"utf-8\", errors=\"replace\") as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "                items.append(json.loads(line))\n",
        "        if items:\n",
        "            print(\"Loaded as UTF-8 JSONL\")\n",
        "            return items\n",
        "    except Exception as e_jl_utf8:\n",
        "        print(f\"UTF-8 JSONL failed: {e_jl_utf8}\")\n",
        "\n",
        "    # Try JSON Lines with cp1252\n",
        "    try:\n",
        "        with open(path, \"r\", encoding=\"cp1252\", errors=\"replace\") as f:\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "                items.append(json.loads(line))\n",
        "        if items:\n",
        "            print(\"Loaded as cp1252 JSONL\")\n",
        "            return items\n",
        "    except Exception as e_jl_cp:\n",
        "        print(f\"cp1252 JSONL failed: {e_jl_cp}\")\n",
        "\n",
        "    raise RuntimeError(f\"Could not parse JSON at {path} with UTF-8/cp1252 or JSONL.\")\n",
        "\n",
        "class PromptOnlyDataset(Dataset):\n",
        "    def __init__(self, prompts, tokenizer, max_length=128):\n",
        "        self.prompts = prompts\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "    def __len__(self):\n",
        "        return len(self.prompts)\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.prompts[idx]\n",
        "        enc = tokenizer(\n",
        "            text,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        return {k: v.squeeze(0) for k, v in enc.items()}\n",
        "\n",
        "def write_targets_for_orders_json(json_path, output_path, batch_size=64):\n",
        "    data = load_json_robust(json_path)\n",
        "\n",
        "    # Support dict-wrapped formats\n",
        "    if isinstance(data, dict):\n",
        "        for k in (\"items\", \"data\", \"orders\"):\n",
        "            if k in data and isinstance(data[k], list):\n",
        "                data = data[k]\n",
        "                break\n",
        "\n",
        "    prompts = [d[\"prompt\"] for d in data if isinstance(d, dict) and \"prompt\" in d]\n",
        "    print(f\"Loaded {len(prompts)} prompts from {json_path}\")\n",
        "\n",
        "    ds = PromptOnlyDataset(prompts, tokenizer, max_length=128)\n",
        "    dl = DataLoader(ds, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model_target.eval()\n",
        "    pred_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in dl:\n",
        "            inputs = {k: v.to(device) for k, v in batch.items()}\n",
        "            logits = model_target(**inputs).logits\n",
        "            pred_idx = torch.argmax(logits, dim=1).cpu().tolist()\n",
        "            pred_labels.extend([idx2label[i] for i in pred_idx])\n",
        "\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        for lbl in pred_labels:\n",
        "            f.write(f\"{lbl}\\n\")\n",
        "\n",
        "    print(f\"Wrote {len(pred_labels)} targets to {output_path}\")\n",
        "\n",
        "# Run once to create the output file\n",
        "write_targets_for_orders_json(input_json, output_txt, batch_size=64)"
      ],
      "metadata": {
        "id": "YvLfeAypsjTz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}